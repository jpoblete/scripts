#!/bin/bash
#
# Script to COPY from a SOURCE table's select columns over a TARGET table
# Assumes the following:
#
# * The SOURCE table is very large - otherwise just try:
#   cqlsh  -e "COPY keyspace.src_table (col1, col2, ...,ColN ) TO STDOUT WITH HEADER=false" \
#   |cqlsh -e "COPY keyspace.tgt_table (col1, col2, ...,ColN ) FROM STDIN"
# * SOURCE AND TARGET TABLES are in the SAME KEYSPACE
# * TARGET columns are named the SAME as SOURCE
#
# The script sweeps thru the local tokens to copy only the local data over to the new table
# Therefore, this script needs to run on every node on the datacenter
#
# Set these variables before executing
#
USR=cassandra
PWD=password
KSP=my_keyspace
SRC=src_table
COL="col1, col2, col3"
PKY="col1"
TGT=tgt_table
TIMEOUT=300

CQLSH="cqlsh -u ${USR} -p ${PWD} -k ${KSP} --request-timeout=${TIMEOUT}"

function getTokens(){
   for i in $($CQLSH -e "select tokens from system.local;" | awk -F, '/{/{print $0}' | tr -d '{' | tr -d '}' | tr -d ','); do
       echo ${i//\'/}
   done | sort -n
}

# When requests per token range timeout and using a larger TIMEOUT does not work
# Break token ranges into subranges to shorten the request execution time
# By default STP=1 - we do not break token ranges
# Practical STP values range between 10-256 
#
function getDataByTokenRange(){
   i=0
   STP=1
   tokens=(-9223372036854775807 $(getTokens))
   while [ ${i} -lt ${#tokens[@]} ]; do
         [ ${i} -eq 0 ]         && echo "SELECT ${COL} FROM ${SRC} WHERE token(${PKY}) <= ${tokens[i]} ALLOW FILTERING;"
         if [ "${tokens[i+1]}" ]; then
            if [ "${STP}" -gt 1 ]; then
               j=0
               range=$(echo "(${tokens[i+1]} - ${tokens[i]})" | bc -l)
               step=$(echo "scale=0; ${range} /${STP}" | bc -l)
               if (( ${range} % ${STP} == 0 )); then
                  subTokens=($(seq ${tokens[i]} ${step} ${tokens[i+1]}))
               else
                  subTokens=($(seq ${tokens[i]} ${step} ${tokens[i+1]}) ${tokens[i+1]})
               fi
               while [ ${j} -lt ${#subTokens[@]} ] && [ "${subTokens[j+1]}" ]; do
                     echo "SELECT ${COL} FROM ${SRC} WHERE token(${PKY}) >  ${subTokens[j]} AND token(${PKY}) <= ${subTokens[j+1]} ALLOW FILTERING;"
                     ((j++))
               done
            else
               echo "SELECT ${COL} FROM ${SRC} WHERE token(${PKY}) >  ${tokens[i]} AND token(${PKY}) <= ${tokens[i+1]};"
            fi
         fi
         [ ! "${tokens[i+1]}" ] && echo "SELECT ${COL} FROM ${SRC} WHERE token(${PKY}) >  ${tokens[i]} ALLOW FILTERING;"
         ((i++))
   done
}

function cqlExec(){
  while IFS='' read -r cql || [[ -n "$line" ]]; do
    $CQLSH -e "CONSISTENCY LOCAL_ONE; $cql"                                             \
    |awk -F\| '( !/LOCAL_ONE/ && !/^\-+/ && !/^\([0-9]+ rows)/ && !/^$/ ){print $0}'    \
    |sed -e 's/^[ ]*//g' -e 's/[ ]*|[ ]*/|/g'                                           \
    |$CQLSH -e "COPY ${TGT} (${COL}) FROM STDIN WITH DELIMITER = '|' and HEADER=true;"
    [ "$?" -gt 0 ] && echo "ERROR: Failed to import data from command: ${command}"
  done < "$1"
}

main(){
   echo "Begin processing ..."
   getDataByTokenRange > getDataByTokenRange.ddl
   cqlExec getDataByTokenRange.ddl
   echo "End processing"
}

main
